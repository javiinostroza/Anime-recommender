{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Users Web Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import time \n",
    "import csv \n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_value(text):\n",
    "    # Función para conseguir el texto entre los markups\n",
    "    text = str(text)\n",
    "    text = text.replace(\"\\n\", \"\").replace(\"\\r\", \"\").replace(\"\\t\", \"\")\n",
    "    markup_count = text.count(\"</\")\n",
    "    position = -1\n",
    "    for i in range(markup_count):\n",
    "        position = text.find(\">\", position + 1)\n",
    "    first_close = text.find(\"</\")\n",
    "    return text[position + 1: first_close]\n",
    "    \n",
    "def get_rating_value(text):\n",
    "    # Función para conseguir el rating con el que se califica un anime\n",
    "    text = str(text)\n",
    "    text = text.replace(\"\\n\", \"\").replace(\"\\r\", \"\").replace(\"\\t\", \"\").replace(\" \", \"\")\n",
    "    rating_text = text.split(':')[-1]\n",
    "    return rating_text.split('<')[0]\n",
    "\n",
    "def get_anime_rating(text):\n",
    "    # Función para conseguir un anime y su rating desde la lista de anime list de un usuario\n",
    "    splited_obj = text.split(',')\n",
    "    if len(splited_obj) == 28:\n",
    "        anime_id = splited_obj[7].split('\"anime_id\":')\n",
    "        print(\"anime:id: \", anime_id, \" largo: \", len(anime_id))\n",
    "        anime = splited_obj[4].split('\"anime_title\":\"')[1][:-1]\n",
    "        rating = splited_obj[0].split(':')[1]\n",
    "        return (anime_id, anime, rating)\n",
    "    return (None, None, None)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def product_male_user_list_data(total_data = 50000):\n",
    "    '''\n",
    "    Scrapping para obtener la calificación de los usuarios a los animé que han visto.\n",
    "    Recibe como parámetro total_data, que corresponde al total de filas que se quiere obtener.\n",
    "    '''\n",
    "\n",
    "    base_url = 'https://myanimelist.net/'\n",
    "    url = 'https://myanimelist.net/users.php?cat=user&q=&loc=&agelow=0&agehigh=0&g=1&show=6028'\n",
    "    actual_url = url\n",
    "    users_information = [[], []] # [ [username], [user gender]]\n",
    "    ratings_information = [[], [], []] # [ [username], [anime], [overall rating] ]\n",
    "    \n",
    "    while True:\n",
    "        print('actual url: ', actual_url)\n",
    "        main_page = requests.get(actual_url)\n",
    "        soup = BeautifulSoup(main_page.content, 'html.parser')\n",
    "        tables = soup.find_all('table')\n",
    "        user_rows = tables[1].find_all('tr')\n",
    "    \n",
    "        for row in user_rows:\n",
    "            user_icons = row.find_all('td')\n",
    "            for icon in user_icons:\n",
    "                \n",
    "                user_name = icon.find('div').find('a')\n",
    "                user_name = get_value(user_name)\n",
    "                users_information[0].append(user_name)\n",
    "                \n",
    "                user_href = icon.find('div').find('a', href=True)\n",
    "                user_url = base_url + user_href['href']\n",
    "                \n",
    "                # Ingresamos al perfil del usuario para obtener género y anime list\n",
    "                time.sleep(randint(1,3))\n",
    "                user_page = requests.get(user_url)\n",
    "                user_soup = BeautifulSoup(user_page.content, 'html.parser')\n",
    "                user_info = user_soup.find('ul', {'class': 'user-status'})\n",
    "                if user_info is None:\n",
    "                    gender = 'Not Found'\n",
    "                else:\n",
    "                    span = user_info.find_all('li')[1].find_all('span')\n",
    "                    if get_value(span[0]) == 'Gender':\n",
    "                        gender = get_value(span[1])\n",
    "                    else:\n",
    "                        gender = 'None'\n",
    "                users_information[1].append(gender)\n",
    "                \n",
    "                # Escribimos los datos del usuario en el csv\n",
    "                with open('male_users.csv', mode='a') as users_file:\n",
    "                    users_writer = csv.writer(users_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "                    users_writer.writerow([user_name, gender]) \n",
    "    \n",
    "                user_lists = user_soup.find('div', {'class': 'user-button clearfix mb12'})\n",
    "                user_anime_list = user_lists.find('a', href=True)\n",
    "                user_anime_list_url = user_anime_list['href']\n",
    "                \n",
    "                # Ingresamos al anime list del usuario\n",
    "                anime_list = requests.get(user_anime_list_url)\n",
    "                anime_list_soup = BeautifulSoup(anime_list.content, 'html.parser')\n",
    "                status_menu = anime_list_soup.find('div', {'class': 'status-menu-container'})\n",
    "                if status_menu:\n",
    "                    try:\n",
    "                        completed_anime_list_url = status_menu.find('a', {'class': 'status-button completed'}, href=True)['href']\n",
    "\n",
    "                        # Ingresamos a anime list completos para extraer su calificacion\n",
    "                        completed_anime_list = requests.get(completed_anime_list_url)\n",
    "                        completed_anime_list_soup = BeautifulSoup(completed_anime_list.content, 'html.parser')\n",
    "                        completed_list = completed_anime_list_soup.find('div', {'class': 'list-unit completed'})\n",
    "\n",
    "                        objects_completed_list = completed_list.find('table')['data-items']\n",
    "                        objects_completed_list = objects_completed_list.split('\"status\":2,')\n",
    "\n",
    "                        # Tomamos los datos de los distintos anime y guardamos el rating\n",
    "                        for _object in objects_completed_list:\n",
    "                            anime_id, anime, rating = get_anime_rating(_object)\n",
    "                            if anime and rating:\n",
    "                                ratings_information[0].append(user_name)\n",
    "                                ratings_information[1].append(anime)\n",
    "                                ratings_information[2].append(rating)\n",
    "                                with open('male_ratings.csv', mode='a') as ratings_file:\n",
    "                                    ratings_writer = csv.writer(ratings_file, delimiter=',', quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
    "                                    ratings_writer.writerow([user_name, anime_id, anime, rating]) \n",
    "\n",
    "                        # Revisamos si conseguimos el total de usuarios que queremos\n",
    "                        print(\"users:info[0]: \", len(users_information[0]), \" total_data: \", total_data)\n",
    "                        if len(users_information[0]) == total_data:\n",
    "                            print(\"break\")\n",
    "                            break\n",
    "                    \n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "\n",
    "            # Revisamos si conseguimos el total de usuarios que queremos\n",
    "            print(\"users:info[0]: \", len(users_information[0]), \" total_data: \", total_data)\n",
    "            if len(users_information[0]) == total_data:\n",
    "                print(\"break\")\n",
    "                break\n",
    "                \n",
    "         # Revisamos si conseguimos el total de usuarios que queremos\n",
    "        print(\"users:info[0]: \", len(users_information[0]), \" total_data: \", total_data)\n",
    "        if len(users_information[0]) == total_data:\n",
    "            print(\"break\")\n",
    "            break\n",
    "        \n",
    "        #Si aún no hemos conseguido la cantidad de datos buscada, cambiamos de url a la siguiente página y realizamos nuevamente el proceso.\n",
    "        if actual_url == 'https://myanimelist.net/users.php?cat=user&q=&loc=&agelow=0&agehigh=0&g=1': \n",
    "            next_page = url + '&show=24'\n",
    "        else:\n",
    "            next_page = '&show=' + str(int(actual_url.split('=')[-1]) + 24)\n",
    "        actual_url = url + next_page\n",
    "  \n",
    "        \n",
    "    return \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "product_male_user_list_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
